# GraphTransformer architecture
type: GraphTransformer
hidden_dim: 64
num_layers: 4
num_heads: 4
dropout: 0.1
use_super_node: false

# FFN & activation
ffn_hidden_dim: null      # if null, defaults to hidden_dim
activation: gelu      # choices: relu, gelu, etc.

# Bias providers
with_spatial_bias: false
num_spatial: 16
with_edge_bias: false
num_edges: 32
with_hop_bias: false
num_hops: 8

# Positional encoders
with_degree_enc: false
max_degree: 10
with_eig_enc: false
num_eigenc: 6
with_svd_enc: false
num_svdenc: 6

# Optional GNN hook
gnn_conv_type: null       # choices: gcn, sage, gat
gnn_position: pre        # choices: pre, post, parallel
